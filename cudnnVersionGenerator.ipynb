{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.compat.v1.keras.layers import CuDNNLSTM\n",
    "from tensorflow.keras.layers import Embedding, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "import string, re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "raw_data_ds = tf.data.TextLineDataset([\"tr_corpus.txt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"\"\n",
    "for elem in raw_data_ds:\n",
    "   text=text+(elem.numpy().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 20\n",
    "step = 3\n",
    "input_chars = []\n",
    "next_char = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(text) - maxlen, step):\n",
    "    input_chars.append(text[i : i + maxlen])\n",
    "    next_char.append(text[i + maxlen])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 378737\n",
      "input X  (input_chars)  --->   output y (next_char) \n",
      "﻿1948 yılında on ark    --->   a\n",
      "48 yılında on arkada    --->   ş\n",
      "yılında on arkadaş,     --->   N\n",
      "ında on arkadaş, Nez    --->   i\n",
      "a on arkadaş, Nezih     --->   B\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of sequences:\", len(input_chars))\n",
    "print(\"input X  (input_chars)  --->   output y (next_char) \")\n",
    "\n",
    "for i in range(5):\n",
    "  print( input_chars[i],\"   --->  \", next_char[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ds_raw=tf.data.Dataset.from_tensor_slices(input_chars)\n",
    "y_train_ds_raw=tf.data.Dataset.from_tensor_slices(next_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_standardization(input_data):\n",
    "    lowercase     = tf.strings.lower(input_data)\n",
    "    stripped_html = tf.strings.regex_replace(lowercase, \"<br />\", \" \")\n",
    "    stripped_num  = tf.strings.regex_replace(stripped_html, \"[\\d-]\", \" \")\n",
    "    stripped_punc  =tf.strings.regex_replace(stripped_num, \"[%s]\" % re.escape(string.punctuation), \"\")    \n",
    "    return stripped_punc\n",
    "\n",
    "def char_split(input_data):\n",
    "  return tf.strings.unicode_split(input_data, 'UTF-8')\n",
    "\n",
    "def word_split(input_data):\n",
    "  return tf.strings.split(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 96   # Number of distinct chars / words\n",
    "embedding_dim = 16             # Embedding layer output dimension\n",
    "sequence_length = maxlen       # Input sequence size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize_layer = TextVectorization(\n",
    "    standardize=custom_standardization,\n",
    "    max_tokens=max_features,\n",
    "    split=char_split, # word_split or char_split\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize_layer.adapt(X_train_ds_raw.batch(batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the vocabulary (number of distinct characters):  55\n"
     ]
    }
   ],
   "source": [
    "print(\"The size of the vocabulary (number of distinct characters): \", len(vectorize_layer.get_vocabulary()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_text(text):\n",
    "  text = tf.expand_dims(text, -1)\n",
    "  return tf.squeeze(vectorize_layer(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(20,), dtype=tf.int64, name=None),\n",
       " TensorSpec(shape=(20,), dtype=tf.int64, name=None))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vectorize the data.\n",
    "X_train_ds = X_train_ds_raw.map(vectorize_text)\n",
    "y_train_ds = y_train_ds_raw.map(vectorize_text)\n",
    "\n",
    "X_train_ds.element_spec, y_train_ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_ds=y_train_ds.map(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds =  tf.data.Dataset.zip((X_train_ds,y_train_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.shuffle(buffer_size=512).batch(batch_size, drop_remainder=True).cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input (X) dimension:  (64, 20) \n",
      "output (y) dimension:  (64,)\n"
     ]
    }
   ],
   "source": [
    "for sample in train_ds.take(1):\n",
    "  print(\"input (X) dimension: \", sample[0].numpy().shape, \"\\noutput (y) dimension: \",sample[1].numpy().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input (sequence of chars):  [ 9 11  3  7  2 11 13 15  8 13 26  9  7  3  6  2 21  3 30  0] \n",
      "output (next char to complete the input):  4\n"
     ]
    }
   ],
   "source": [
    "for sample in train_ds.take(1):\n",
    "  print(\"input (sequence of chars): \", sample[0][0].numpy(), \"\\noutput (next char to complete the input): \",sample[1][0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence (encoded_sequence):\n",
    "  deceoded_sequence=[]\n",
    "  for token in encoded_sequence:\n",
    "    deceoded_sequence.append(vectorize_layer.get_vocabulary()[token])\n",
    "  sequence= ''.join(deceoded_sequence)\n",
    "  print(sequence.capitalize())\n",
    "  return sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acıkır mülk köyü s\n",
      "input (sequence of chars):  acıkır mülk köyü s \n",
      "output (next char to complete the input):  i\n"
     ]
    }
   ],
   "source": [
    "for sample in train_ds.take(1):\n",
    "  print(\"input (sequence of chars): \", decode_sequence (sample[0][0].numpy()), \"\\noutput (next char to complete the input): \",vectorize_layer.get_vocabulary()[sample[1][0].numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(z):\n",
    "   return np.exp(z)/sum(np.exp(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temperature_sampling (conditional_probability, temperature=1.0):\n",
    "  conditional_probability = np.asarray(conditional_probability).astype(\"float64\")\n",
    "  conditional_probability = np.log(conditional_probability) / temperature\n",
    "  reweighted_conditional_probability = softmax(conditional_probability)\n",
    "  probas = np.random.multinomial(1, reweighted_conditional_probability, 1)\n",
    "  return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(sequence_length), dtype=\"int64\")\n",
    "x = Embedding(max_features, embedding_dim)(inputs)\n",
    "x = CuDNNLSTM(256,return_sequences=True)(x)\n",
    "x = CuDNNLSTM(256, return_sequences=True)(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = CuDNNLSTM(256, return_sequences=True)(x)\n",
    "x = Flatten()(x)\n",
    "predictions=  Dense(max_features, activation='softmax')(x)\n",
    "model = tf.keras.Model(inputs, predictions,name=\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 20)]              0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 20, 16)            1536      \n",
      "                                                                 \n",
      " cu_dnnlstm (CuDNNLSTM)      (None, 20, 256)           280576    \n",
      "                                                                 \n",
      " cu_dnnlstm_1 (CuDNNLSTM)    (None, 20, 256)           526336    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 20, 256)           0         \n",
      "                                                                 \n",
      " cu_dnnlstm_2 (CuDNNLSTM)    (None, 20, 256)           526336    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 5120)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 96)                491616    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,826,400\n",
      "Trainable params: 1,826,400\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Eğitim sonlandırıldı.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    model.fit(train_ds,epochs=17)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nEğitim sonlandırıldı.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"TRcudnn_version.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"cudnn_version.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, seed_original, step,temperatures=[]):\n",
    "    seed_original=seed_original.lower()\n",
    "    seed= vectorize_text(seed_original)\n",
    "    print(\"The prompt is :\",end=\"\")\n",
    "    decode_sequence(seed.numpy().squeeze())\n",
    "    seed= vectorize_text(seed_original).numpy().reshape(1,-1)\n",
    "    #Text Generated by Temperature Sampling\n",
    "    for temperature in temperatures:\n",
    "        print(\"Temperature: \", temperature)\n",
    "        seed= vectorize_text(seed_original).numpy().reshape(1,-1)\n",
    "        generated_temperature = (seed)\n",
    "        for i in range(step):\n",
    "            predictions=model.predict(seed)\n",
    "            next_index = temperature_sampling(predictions.squeeze(), temperature)\n",
    "            generated_temperature = np.append(generated_temperature, next_index)\n",
    "            seed= generated_temperature[-sequence_length:].reshape(1,sequence_length)\n",
    "        print(\"Output: \",end=\"\")\n",
    "        decode_sequence(generated_temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt is :Charlie and john \n",
      "Temperature:  0.3\n",
      "Output: Charlie and john elıniluakeat e  ç                                                                             \n"
     ]
    }
   ],
   "source": [
    "generate_text(model,\"Charlie and john \",95,[0.2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
